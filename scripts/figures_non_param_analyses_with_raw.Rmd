---
title: "Access regime stewardship analysis "
author: "Ignacia Rivera"
date: "July 21, 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gt)
library(here)
library(tidyverse)
library(sandwich)
library(lmtest)
library(nlme)
library(lme4)
library(censReg)
```

## Metadata 

1) union: unique id for each union (not diclosed to ensure anonimity)
 
2) performance: type of association 

- High performance =1
- Low performance =2 

3) framing: framing under which the game was played

- Loco = 1 
- Hake = 2 

4) id: unique identifier for each fisher

5) round: round of the game

- From 1 to 20

6) overextraction: number of units overharvested by a subject in a given round

- From 0 to 50

7) observer: the role assigned to that subject in that round 

- Observer = 1
- Inactive = -1
- Inspected = 0
- Round with no observation = NA

8) overext_observed: overextraction performed by the subject being inspected by the subject 

- From 0 to 50
- Round with no observation = NA

9) report: whether the subject reported a parnter's violation when having the chance

- Yes = 1
- No = 0
- Round with no obsrevation = NA

10) punished: whether the subject got punished after being observed violating the quota 

- Yes = 1
- No = 0
- Round with no obsrevation = NA

11) round_profit: profit made by the subject in a given round

- From 0 to 1,500

12) group_id: unique number for group identification built combaning codes for union, session and frame

```{r Importing raw experiment data, echo = FALSE, message=FALSE, warning=FALSE, include=FALSE}

DB <- read_csv(here::here('data/DB_raw.csv'), col_names = T) %>%
  filter(trial == 0,   
        !(performance == 3),
        !(framing == 3)) %>% 
  mutate(group_id = interaction(union, group, framing, sep=''),
         id = interaction(id, union, framing, sep=''),
         round = ifelse(round <= 13, round - 3, round - 6),
         overext_observed = ifelse(observer == 1, overext_observed, NA),
         report= ifelse(observer == 1, report, NA),
         punished = ifelse(observer == 0, punished, NA),
         observer = ifelse(round < 11, NA, observer))%>% 
  # group id with single group for las cruces sessions given random matching
         mutate(group_id_fixed = ifelse(
           union ==3 & framing ==1, "888", 
           ifelse( union ==3 & framing == 2, "999", as.character(group_id)))) %>%
         mutate(group_id = as.character(group_id)) %>%
         select(-(group)) 
  

# Generating variables

DB <- DB %>% 
  mutate(compliance = ((50 - overextraction) * 100)/50, #individual percent of compliance in each round
         stage = ifelse(round < 11 , 1, 2), # generating dicotomic variable for stage
         stage.nm = ifelse(round < 11 , "Nonenforced", "Peer-enforced"), # generating character for stage
         frame.nm = ifelse(framing == 1, 'Loco', 'Hake'), # generating character variable for frame
         frame.nm = factor(frame.nm, levels = c('Hake', 'Loco')), # sorting names of frames
         performance.nm = ifelse(performance == 1, 'High performance', 'Low performance')) 

head(DB)

```

## 1. Compliance behavior

### 1.a. Nonparametric tests for differences in individual mean compliance
```{r non-parametric comparisons of compliance, echo = FALSE, message=FALSE, warning=FALSE}

# Aggregating observations at the individual level 

db.ind.agg <- DB %>% 
  group_by(frame.nm, performance.nm, stage.nm, id) %>% 
  summarise(compliance= mean(compliance)) %>% 
  select(-id) 


# Testing significant differences between frames for each association type across all rounds

frame.comp <- db.ind.agg %>%
  group_by(performance.nm) %>% 
  summarize(p.value = wilcox.test(compliance ~ frame.nm)$p.value, 
            stat = wilcox.test(compliance ~ frame.nm)$statistic) %>% 
  mutate(frame.nm = 'vs',
         stage.nm = 'All')

# Testing significant differences between association type for each frame across all rounds

performance.comp <- db.ind.agg %>%
  group_by(frame.nm) %>% 
  summarize(p.value = wilcox.test(compliance ~ performance.nm)$p.value, 
            stat = wilcox.test(compliance ~ performance.nm)$statistic) %>% 
  mutate(performance.nm = 'vs',
         stage.nm = 'All')


# Testing significant differences between stages since observations are repeated it must be a paired test

stages.comp <- db.ind.agg %>% 
  group_by(frame.nm, performance.nm) %>% 
  summarize(p.value = wilcox.test(compliance ~ stage.nm, paired = T)$p.value,
            stat = wilcox.test(compliance ~  stage.nm, paired = T)$statistic) %>% 
  mutate(stage.nm = 'vs')

# Unifying outputs

test.comp <- rbind(frame.comp, performance.comp, stages.comp) %>% 
  select(performance= performance.nm, frame = frame.nm, stage= stage.nm, p.value, stat) %>% 
  mutate(corrected.p.value = p.value * 8, 
         sign.corrected = ifelse(corrected.p.value < 0.05,"*", ""))  # Correcting for 8 hypotheses using Bonferroni

wilx.com <- gt(test.comp) %>% 
   fmt_number(columns = vars(p.value), decimals = 3) %>% 
  tab_header(
    title = md("Nonparametric Wilcoxon rank-sum test to test differences in compliance levels")
  ) %>% 
  tab_source_note(
    source_note = md("Significance level is ajusted using a Bonferroni correction for 8 hypotheses")
  )%>% 
  tab_source_note(
    source_note = md("Tests comparing differences between stages are paired")
  )

wilx.com
```

### 1.b. Mean individual compliance per treatment plot
```{r bar plot mean compliance, echo = FALSE, message=FALSE, warning=FALSE}

#stats_compliance <- read_csv(here::here('Data/summary_stats.csv'), col_names = T)
#stats_compliance$Frame <- factor(stats_compliance$Frame, levels = c("Loco", "Hake"))

db.summary <- DB %>% 
  group_by(performance.nm, frame.nm, id) %>% 
  summarise(mean.ind = mean(compliance)) %>% 
  ungroup() %>% 
  group_by(performance.nm, frame.nm) %>% 
  summarise(mean = mean(mean.ind),
          sd = sd(mean.ind),
          n = length(mean.ind)) %>% 
  mutate(error = qnorm(0.975)*(sd/sqrt(n)), 
         ci.low = mean - error, 
         ci.high = mean + error) %>% 
  rename(
    Performance = performance.nm,
    Frame = frame.nm
  )

bar_compliance <- ggplot(db.summary, aes(x=Performance, y= mean, fill= reorder(Frame, -mean))) + 
  geom_bar(stat='identity', width=0.5, position=position_dodge(0.6))+
  geom_errorbar(aes(x= Performance, ymin = ci.low, ymax= ci.high), width=0.25, position=position_dodge(0.6), size = 0.4)+
  scale_fill_manual(values = c("royalblue3", "red1"), labels = c("CEAR (Loco)", "pseudo OA (Hake)"))+
  xlab(expression(bold("Association Type")))+
  ylab(expression(bold("Compliance (%)")))+
  scale_y_continuous(expand = c(0, 0), limits=c(0,100), breaks=seq(0,100, by=20))+
  #facet_wrap(~Performance)+
  scale_x_discrete(labels=c("1" = "High-performance", "2" = "Low-performance"))+ 
  theme_bw()+
  theme(legend.position="bottom", legend.title=element_blank(), legend.text = element_text(size=10, margin = margin(t= 10, r= 0, b =0, l =0)), 
        panel.grid = element_blank(), 
        strip.text = element_text(size=11), 
        axis.title = element_text(size = 12), 
        axis.text = element_text(size = 11), 
        axis.title.y = element_text(margin = margin(t = 0, r = 8, b = 0, l = 0)), 
        axis.title.x = element_text(margin = margin(t = 8, r = 0, b = 0, l = 0)))

bar_compliance
#ggsave("Fig1_rev.jpg", plot = bar_compliance, device = "jpg", path = here::here("figures"), scale = 1, width = 16, height = 12, units = "cm", dpi = 300, limitsize = TRUE)

```

### 1.c. Comparing number of subjects that choose to comply in every round between treatments

```{r analysis for subjects that choose to comply in every round, echo = FALSE, message=FALSE, warning=FALSE, include=FALSE}

# Counting number of compliers in every round

db.compliers <- DB %>% 
  group_by(frame.nm, performance.nm, id) %>% 
  summarise(compliance= mean(compliance)) %>% 
  mutate(complier = ifelse(compliance == 100, 1, 0)) %>% 
  group_by(frame.nm, performance.nm) %>% 
  summarise(n.compliers = sum(complier))

# Contingency table of compliers for high performance associations (compliers vs. non-compliers in each treatment)

table.compliers.hp <- rbind(
        #cear
        c(10,20),
        #oa
        c(2,28))

# Running fisher exact test and correcting for two hypotheses 

fisher.compliers.hp <- fisher.test(table.compliers.hp)$p.value*2 

# Contingency table of compliers for low performance associations (compliers vs. non-compliers in each treatment)

table.compliers.lp <- rbind(
        #cear
        c(2,28),
        #oa
        c(1,29))

# Running fisher exact test and correcting for two hypotheses 

fisher.compliers.lp <- fisher.test(table.compliers.lp)$p.value*2 


```

### 1.e. Regressions on compliance accounting for group correlation

```{r individual database, echo = FALSE, include = FALSE}

db.ind <- DB %>% 
  # creating context variables 
  mutate(
    cear = ifelse(frame.nm == 'Loco', 1, 0), 
    peer_enf = ifelse(stage.nm == 'Peer-enforced', 1, 0), 
    hp = ifelse(performance.nm == 'High performance', 1, 0), 
    non_enf_rounds = ifelse(round < 11, round-1,0), 
    peer_enf_rounds = ifelse(round > 10, round - 11, 0), 
    cear_peer_enf = ifelse(frame.nm == 'Loco' 
                           & stage.nm == 'Peer-enforced', 1, 0), 
    cear_hp = ifelse(frame.nm == 'Loco' 
                           & performance.nm == 'High performance', 1, 0), 
    peer_enf_hp = ifelse(stage.nm == 'Peer-enforced' &
                                  performance.nm == 'High performance', 1, 0), 
    cear_hp_non_enf_rounds = ifelse(frame.nm == 'Loco'&
                                    performance.nm == 'High performance'& 
                                    round < 11, 
                                    round - 1, 0), 
    cear_hp_peer_enf_rounds = ifelse(frame.nm == 'Loco' &
                                    performance.nm == 'High performance'& 
                                    round > 10,
                                    round - 11, 0), 
    oa_hp_non_enf_rounds = ifelse(frame.nm == 'Hake'&
                                    performance.nm == 'High performance'& 
                                    round < 11, 
                                    round - 1, 0),
    oa_hp_peer_enf_rounds = ifelse(frame.nm == 'Hake'&
                                    performance.nm == 'High performance'& 
                                    round > 10, 
                                    round - 11, 0),
    cear_lp_non_enf_rounds = ifelse(frame.nm == 'Loco'&
                                    performance.nm == 'Low performance'& 
                                    round < 11, 
                                    round - 1, 0), 
    cear_lp_peer_enf_rounds = ifelse(frame.nm == 'Loco'&
                                    performance.nm == 'Low performance'& 
                                    round > 10, 
                                    round - 11, 0), 
    oa_lp_non_enf_rounds = ifelse(frame.nm == 'Hake'&
                                    performance.nm == 'Low performance'& 
                                    round < 11, 
                                    round - 1, 0),
    oa_lp_peer_enf_rounds = ifelse(frame.nm == 'Hake'&
                                    performance.nm == 'Low performance'& 
                                    round > 10, 
                                    round - 11, 0)) %>% 
  # creating variables in Cassari and Luni, 2009
  ## avg compliance in non-enf stage per individual
  group_by(id) %>%
  mutate(avg_comp_non_enf = mean(compliance[round<11])) %>% 
  ungroup() %>% 
  ## avg compliance and overharvest in the group
  group_by(group_id, round) %>% 
  mutate(sum_comp = sum(compliance),
         avg_group_comp = sum_comp/5) %>% 
  ungroup() %>% 
  ## avg compliance of other group members
  mutate(avg_oth_comp = (sum_comp - compliance)/4) %>% 
  group_by(id) %>% 
  ## avg compliance of other group members in previous round 
  mutate(avg_oth_comp_prev = dplyr::lag(avg_oth_comp, n=1),
         ## average group compliance in the previous round
         avg_group_comp_prev = dplyr::lag(avg_group_comp, n=1),
         ## subject was punished in previous round
         punished_prev_round = ifelse(is.na(dplyr::lag(punished)), 0, dplyr::lag(punished)),
         ## subject was punished in the second previous round
         punished_prev_prev_round = dplyr::lag(punished_prev_round),
         ## the subject choose to report in the previous round
         report_prev_round = ifelse(is.na(dplyr::lag(report)), 0, dplyr::lag(report))) %>% 
  ungroup() %>% 
  mutate(## observed compliance 
         obs_comp = ifelse(is.na(overext_observed), 0,((50 - overext_observed) * 100)/50),
         ## deviation of inspected relative to average group compliance in prev round
         comp_inspected_deviation = obs_comp - avg_group_comp_prev,
         ## positive deviation of inspected relative to average group compliance in prev round
         pos_comp_inspected_deviation = ifelse(comp_inspected_deviation > 0 , comp_inspected_deviation, 0),
         ## negative deviation of inspected relative to average group compliance in prev round
         neg_comp_inspected_deviation = ifelse(comp_inspected_deviation < 0 , abs(comp_inspected_deviation), 0),
         # subject’s compliance minus average group’s compliance in the previous round
         diff_comp_group_comp_prev = compliance - avg_oth_comp_prev) 
  
```

#### 1.e1 Linear models with frame, association type and stage interactions with random effects per group 

```{r Linear models with frame, association type and stage interactions with random effects per group, echo = FALSE, include = FALSE}

comp_ind_1_re <- lme(compliance ~ cear, na.action= na.exclude, data = db.ind, random = ~1|group_id_fixed)

comp_ind_2_re <- lme(compliance ~ cear + peer_enf + hp, na.action= na.exclude, data = db.ind, random = ~1|group_id_fixed)

comp_ind_3_re <- lme(compliance ~ cear + peer_enf + hp + non_enf_rounds + peer_enf_rounds, na.action= na.exclude, data = db.ind, random = ~1|group_id_fixed)

comp_ind_4_re <- lme(compliance ~ cear + peer_enf + hp + cear_peer_enf + cear_hp + peer_enf_hp, na.action= na.exclude, data = db.ind, random = ~1|group_id_fixed)

comp_ind_5_re <- lme(compliance ~ cear + peer_enf + hp + non_enf_rounds + peer_enf_rounds + cear_peer_enf + cear_hp + peer_enf_hp, na.action= na.exclude, data = db.ind, random = ~1|group_id_fixed)

comp_ind_6_re <- lme(compliance ~ cear + peer_enf + hp + cear_peer_enf + cear_hp + peer_enf_hp +  cear_hp_non_enf_rounds + cear_hp_peer_enf_rounds + oa_hp_non_enf_rounds + oa_hp_peer_enf_rounds + cear_lp_non_enf_rounds + cear_lp_peer_enf_rounds + oa_lp_non_enf_rounds + oa_lp_peer_enf_rounds, na.action= na.exclude, data = db.ind, random = ~1|group_id_fixed)



summary(comp_ind_1_re)
summary(comp_ind_2_re)
summary(comp_ind_3_re)
summary(comp_ind_4_re)
summary(comp_ind_5_re)
summary(comp_ind_6_re)
```
 
#### 1.e2 Linear models with frame, association type and stage interactions with clustered errors per group 

```{r Linear models with frame, association type and stage interactions with errors clustered per group, echo = FALSE, include = FALSE}

library(miceadds)

comp_ind_1_clu <- lm.cluster(data = db.ind, formula = compliance ~ cear, cluster = db.ind$group_id_fixed)

comp_ind_2_clu <- lm.cluster(data = db.ind, formula = compliance ~ cear + peer_enf + hp, cluster = 'group_id_fixed')

comp_ind_3_clu <- lm.cluster(data = db.ind, formula = compliance ~ cear + peer_enf + hp + non_enf_rounds + peer_enf_rounds, cluster = 'group_id_fixed')

comp_ind_4_clu <- lm.cluster(data = db.ind, formula = compliance ~ cear + peer_enf + hp + cear_peer_enf + cear_hp + peer_enf_hp, cluster = 'group_id_fixed')

comp_ind_5_clu <- lm.cluster(data = db.ind, formula = compliance ~ cear + peer_enf + hp + non_enf_rounds + peer_enf_rounds + cear_peer_enf + cear_hp + peer_enf_hp, cluster = 'group_id_fixed')

comp_ind_6_clu <- lm.cluster(data = db.ind, formula = compliance ~ cear + peer_enf + hp + cear_peer_enf + cear_hp + peer_enf_hp +  cear_hp_non_enf_rounds + cear_hp_peer_enf_rounds + oa_hp_non_enf_rounds + oa_hp_peer_enf_rounds + cear_lp_non_enf_rounds + cear_lp_peer_enf_rounds + oa_lp_non_enf_rounds + oa_lp_peer_enf_rounds, cluster = 'group_id_fixed')



summary(comp_ind_1_clu)
summary(comp_ind_2_clu)
summary(comp_ind_3_clu)
summary(comp_ind_4_clu)
summary(comp_ind_5_clu)
summary(comp_ind_6_clu)
```

#### 1.e3 Compliance computed at the group level

```{r Linear models of group compliance with frame, association type and stage interactions, echo = FALSE}

db.group <- DB %>% 
  # filter(union != 3) %>% 
  # signaling punishment opportunities 
  mutate(report.opportunity = ifelse(observer ==1 & overext_observed > 0, 1, 0)) %>% 
   group_by(frame.nm, performance.nm, stage.nm, round, group_id_fixed) %>%
  # group_by(frame.nm, performance.nm, stage.nm, round, group_id) %>% 
  # computing outcome variables at the group level
  summarise(mean.group.com = mean(compliance),
            num.opp.reporting = sum(report.opportunity, na.rm = T),
            num.reports = sum(report, na.rm = T), 
            group.prob.report = num.reports / num.opp.reporting,
            mean.obs.overharvest = mean(overext_observed, na.rm = T)) %>%  
  # creating context variables 
  mutate(
    cear = ifelse(frame.nm == 'Loco', 1, 0), 
    peer_enf = ifelse(stage.nm == 'Peer-enforced', 1, 0), 
    hp = ifelse(performance.nm == 'High performance', 1, 0), 
    non_enf_rounds = ifelse(round < 11, round-1,0), 
    peer_enf_rounds = ifelse(round > 10, round - 11, 0), 
    cear_peer_enf = ifelse(frame.nm == 'Loco' 
                           & stage.nm == 'Peer-enforced', 1, 0), 
    cear_hp = ifelse(frame.nm == 'Loco' 
                           & performance.nm == 'High performance', 1, 0), 
    oa_hp = ifelse(frame.nm == 'Hake' 
                           & performance.nm == 'High performance', 1, 0),
    cear_lp = ifelse(frame.nm == 'Loco' 
                           & performance.nm == 'Low performance', 1, 0),
    oa_lp = ifelse(frame.nm == 'Hake' 
                           & performance.nm == 'Low performance', 1, 0),
    peer_enf_hp = ifelse(stage.nm == 'Peer-enforced' &
                                  performance.nm == 'High performance', 1, 0), 
    cear_hp_non_enf_rounds = ifelse(frame.nm == 'Loco'&
                                    performance.nm == 'High performance'& 
                                    round < 11, 
                                    round - 1, 0), 
    cear_hp_peer_enf_rounds = ifelse(frame.nm == 'Loco' &
                                    performance.nm == 'High performance'& 
                                    round > 10,
                                    round - 11, 0), 
    oa_hp_non_enf_rounds = ifelse(frame.nm == 'Hake'&
                                    performance.nm == 'High performance'& 
                                    round < 11, 
                                    round - 1, 0),
    oa_hp_peer_enf_rounds = ifelse(frame.nm == 'Hake'&
                                    performance.nm == 'High performance'& 
                                    round > 10, 
                                    round - 11, 0),
    cear_lp_non_enf_rounds = ifelse(frame.nm == 'Loco'&
                                    performance.nm == 'Low performance'& 
                                    round < 11, 
                                    round - 1, 0), 
    cear_lp_peer_enf_rounds = ifelse(frame.nm == 'Loco'&
                                    performance.nm == 'Low performance'& 
                                    round > 10, 
                                    round - 11, 0), 
    oa_lp_non_enf_rounds = ifelse(frame.nm == 'Hake'&
                                    performance.nm == 'Low performance'& 
                                    round < 11, 
                                    round - 1, 0),
    oa_lp_peer_enf_rounds = ifelse(frame.nm == 'Hake'&
                                    performance.nm == 'Low performance'& 
                                    round > 10, 
                                    round - 11, 0), 
    weights = ifelse(group_id_fixed == '999' | group_id_fixed == '888', 2, 1))

comp_grp_1 <- lm(mean.group.com ~ cear, data = db.group, weights = weights)

comp_grp_2 <- lm(mean.group.com ~ cear + peer_enf + hp, data = db.group, weights = weights)

comp_grp_3 <- lm(mean.group.com ~ cear + peer_enf + hp + non_enf_rounds + peer_enf_rounds, data = db.group, weights = weights)

comp_grp_4 <- lm(mean.group.com ~ cear + peer_enf + hp + cear_peer_enf + cear_hp + peer_enf_hp, data = db.group, weights = weights)

comp_grp_5 <- lm(mean.group.com ~ cear + peer_enf + hp + non_enf_rounds + peer_enf_rounds + cear_peer_enf + cear_hp + peer_enf_hp, data = db.group, weights = weights)

comp_grp_6 <- lm(mean.group.com ~ cear + peer_enf + hp + cear_peer_enf + cear_hp + peer_enf_hp +  cear_hp_non_enf_rounds + cear_hp_peer_enf_rounds + oa_hp_non_enf_rounds + oa_hp_peer_enf_rounds + cear_lp_non_enf_rounds + cear_lp_peer_enf_rounds + oa_lp_non_enf_rounds + oa_lp_peer_enf_rounds, data = db.group, weights = weights)

summary(comp_grp_1)
summary(comp_grp_2)
summary(comp_grp_3)
summary(comp_grp_4)
summary(comp_grp_5)
summary(comp_grp_6)
```

## 2. Reporting behavior

### 2.a. Nonparametric test for punishment probability

```{r non-parametric comparisons of punishment probability, echo = FALSE, message=FALSE, warning=FALSE, include=FALSE}

# Filtering only first and last round of nonenforced stage

db.punish <- DB %>% 
  filter(round > 10) %>% 
  mutate(punish.opportunity = ifelse(observer ==1 & overext_observed > 0, 1, 0)) %>% 
  group_by(frame.nm, performance.nm, id) %>% 
  summarise(prob.punish = sum(report, na.rm=T)/sum(punish.opportunity, na.rm=T)) %>% 
  select(-id) %>% 
  filter(!(prob.punish == 'NaN'))

n.punish <- db.punish %>% 
  group_by(frame.nm, performance.nm) %>% 
  summarise(n = length(prob.punish))

# Testing significant differences between first and last round for each frame performance combination in nonenforced stage

test.punish.frame <- db.punish %>%
  group_by(performance.nm) %>% 
  summarize(p.value = wilcox.test(prob.punish ~ as.factor(frame.nm))$p.value, 
            statistic = wilcox.test(prob.punish ~ as.factor(frame.nm))$statistic) %>% 
  mutate(frame.nm = 'vs')

test.punish.performance <- db.punish %>%
  group_by(frame.nm) %>% 
  summarize(p.value = wilcox.test(prob.punish ~ as.factor(performance.nm))$p.value, 
            statistic = wilcox.test(prob.punish ~ as.factor(performance.nm))$statistic) %>% 
  mutate(performance.nm = 'vs') 


test.punish <- rbind(test.punish.frame, test.punish.performance) %>% 
  mutate(corrected.p.value = p.value * 4, 
         sign.corrected = ifelse(corrected.p.value < 0.05,"*", "")) %>% 
  select(performance.nm, frame.nm, statistic, p.value, corrected.p.value)

gt(test.punish) %>% 
   fmt_number(columns = vars(p.value), decimals = 3) %>% 
  tab_header(
    title = md("Nonparametric Wilcoxon rank-sum test to test differences in probability of punishment")
  ) %>% 
  tab_source_note(
    source_note = md("Significance level is ajusted using a Bonferroni correction for 4 hypotheses")
  )%>% 
  tab_source_note(
    source_note = md("Tests comparing differences between stages are paired")
  )
```

### 2.b. Punishment plot
```{r punishment plot, echo = FALSE, message=FALSE, warning=FALSE, include=FALSE}
# Filtering only first and last round of nonenforced stage

db.punish.plot<- db.punish %>% 
  group_by(frame.nm, performance.nm) %>% 
  summarise(mean = mean(prob.punish),
          sd = sd(prob.punish),
          n = length(prob.punish)) %>% 
  mutate(error = qnorm(0.975)*(sd/sqrt(n)), 
         ci.low = mean - error, 
         ci.high = mean + error) %>% 
  rename(
    Performance = performance.nm,
    Frame = frame.nm
  )

plot_report <- ggplot(db.punish.plot, aes(x= Performance, y= mean, fill= reorder(Frame, -mean))) + 
  geom_bar(stat='identity', width=0.5, position=position_dodge(0.6))+
  geom_errorbar(aes(x=as.factor(Performance), ymin = ci.low, ymax= ci.high), width=0.25, position=position_dodge(0.6), size = 0.4)+
  scale_fill_manual(values = c("royalblue3", "red1"), labels = c("CEAR (Loco)", "pseudo OA (Hake)"))+
  xlab(expression(bold("Performance")))+
  ylab(expression(bold("Punishment probability")))+
  scale_y_continuous(expand = c(0, 0), limits=c(0,1), breaks=seq(0,1, by=0.2))+
  #facet_wrap(~Performance)+
  #scale_x_discrete(labels=c("1" = "High-performance", "2" = "Low-performance"))+ 
  theme_bw()+
  theme(legend.position="bottom", legend.title=element_blank(), legend.text = element_text(size=10, margin = margin(t= 10, r= 0, b =0, l =0)), 
        panel.grid = element_blank(), 
        strip.text = element_text(size=11), 
        axis.title = element_text(size = 12), 
        axis.text = element_text(size = 11), 
        axis.title.y = element_text(margin = margin(t = 0, r = 8, b = 0, l = 0)), 
        axis.title.x = element_text(margin = margin(t = 8, r = 0, b = 0, l = 0)))

#ggsave("Fig2.pdf", plot = plot_report, device = "pdf", path = here::here("figures"), scale = 1, width = 16, height = 12, units = "cm", dpi = 300, limitsize = TRUE)


```

### 2.c. Evolution of probabibilty of report over rounds per treatment 

```{r probability of reporting evolution, echo = FALSE, warning= FALSE, include=FALSE}


db.punish.round <- DB %>% 
  filter(round > 10) %>% 
  mutate(punish.opportunity = ifelse(observer ==1 & overext_observed > 0, 1, 0)) %>% 
  group_by(frame.nm, performance.nm, round) %>% 
  summarise(prob.punish = sum(report, na.rm=T)/sum(punish.opportunity, na.rm=T)) %>% 
  filter(!(prob.punish == 'NaN')) %>% 
  mutate(stage.three = case_when(round == 11 ~ 'Early',
                                 round == 12 ~ 'Early', 
                                 round == 13 ~ 'Early',
                                 round == 14 ~ 'Mid',
                                 round == 15 ~ 'Mid',
                                 round == 16 ~ 'Mid',
                                 round == 17 ~ 'Mid',
                                 round == 18 ~ 'Late',
                                 round == 19 ~ 'Late',
                                 round == 20 ~ 'Late')) %>% 
  group_by(performance.nm, frame.nm, stage.three) %>% 
  summarize(mean.prob.reporting = mean(prob.punish),
            sd = sd(prob.punish),
            n = length(prob.punish)) %>% 
  ungroup() %>% 
  mutate(error = qnorm(0.975)*(sd/sqrt(n)), 
         ci.low = mean.prob.reporting - error, 
         ci.high = mean.prob.reporting + error,
         stage.three = factor(stage.three, levels = c("Early", "Mid", "Late"))) %>% 
  ggplot(aes(x= stage.three, y= mean.prob.reporting, group=frame.nm)) +
  geom_line(aes(col= frame.nm), size = 0.64) +
  geom_point(aes(col = frame.nm), size = 1.3) +
  geom_errorbar(aes(ymin=ci.low, ymax= ci.high, col = frame.nm), width= 0.28) +
  scale_color_manual(values = c("red1", "royalblue3"), labels = c("pseudo OA (Hake)", "CEAR (Loco)"))+
  scale_fill_manual(values = c("red1", "royalblue3"), labels = c("pseudo OA (Hake)", "CEAR (Loco)"))+
  theme_bw() + 
  xlab(expression(bold("Stage"))) +
  ylab(expression(bold("Probability of reporting")))+
  #scale_x_continuous(expand = c(0,0), breaks=c(seq(1,20,1)), labels = c(seq(0,9,1), seq(0,9,1)))+
  scale_y_continuous(limits = c(-0.1, 1.1), breaks = c(seq(-0.1,1.1,0.5)), expand = c(0,0))+
  #geom_vline(xintercept=10.5, size=5.4, col= 'white')+
  facet_wrap(~performance.nm)+
  theme(legend.position="bottom", legend.title=element_blank(), legend.text =    element_text(size=11),
        panel.grid = element_blank(), plot.title = element_text(hjust = 0.5), panel.grid.major =
          element_blank(), panel.grid.minor = element_blank())+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        #strip.background = element_blank(),
        strip.text = element_text(size= 10, hjust = 0, vjust = 1),
        panel.border = element_rect(colour = "dark grey"), 
        panel.spacing.x=unit(1, "lines"), 
        axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0)), 
        axis.title = element_blank(), 
        axis.text = element_text(size = 10),
        plot.title = element_text(size= 11, face= "bold", hjust = 0, vjust = 1))

```


### 2.d. Regressions on the group probability of reporting 

```{r Linear models of group reporting with frame, association type and stage interactions, echo = FALSE}

report_grp_1 <- lm(group.prob.report ~ cear, data = subset(db.group, db.group$round > 10), weights = weights)

report_grp_2 <- lm(group.prob.report ~ cear + round + mean.obs.overharvest, data = subset(db.group, db.group$round > 10), weights = weights)

report_grp_3 <- lm(group.prob.report ~ cear + hp, data = subset(db.group, db.group$round > 10), weights = weights)

report_grp_4 <- lm(group.prob.report ~ cear + round + mean.obs.overharvest + hp, data = subset(db.group, db.group$round > 10), weights = weights)

report_grp_5 <- lm(group.prob.report ~ cear + hp + cear_hp, data = subset(db.group, db.group$round > 10), weights = weights)

report_grp_6 <- lm(group.prob.report ~ cear + round + mean.obs.overharvest + hp + cear_hp, data = subset(db.group, db.group$round > 10), weights = weights)

report_grp_7 <- lm(group.prob.report ~ oa_hp + cear_lp + oa_lp, data = subset(db.group, db.group$round > 10), weights = weights)

report_grp_8 <- lm(group.prob.report ~ + round + mean.obs.overharvest + oa_hp + cear_lp + oa_lp, data = subset(db.group, db.group$round > 10), weights = weights)

summary(report_grp_1)
summary(report_grp_2)
summary(report_grp_3)
summary(report_grp_4)
summary(report_grp_5)
summary(report_grp_6)
summary(report_grp_7)
summary(report_grp_8)
```


### 1.c. Nonparametric tests for evolution of compliance
```{r non-parametric comparisons of first and last rounds per treatment, echo = FALSE, message=FALSE, warning=FALSE, include=FALSE}

# Filtering only first and last round of nonenforced stage

db.evol.nonenf <- DB %>% 
  filter(round == 1|round == 10)

# Testing significant differences between first and last round for each frame performance combination in nonenforced stage

evol.nonenf <- db.evol.nonenf %>%
  group_by(performance.nm, frame.nm) %>% 
  summarize(p.value = wilcox.test(compliance ~ as.factor(round), paired = T)$p.value,
            statistic = wilcox.test(compliance ~ as.factor(round), paired = T)$statistic) %>% 
  mutate(stage = "nonenforced")

# Filtering only first and last round of peer-enforced stage

db.evol.peerenf <- DB %>% 
  filter(round == 11|round == 20)

# Testing significant differences between first and last round for each frame performance combination in peer-enforced stage

evol.peerenf <- db.evol.peerenf %>%
  group_by(performance.nm, frame.nm) %>% 
  summarize(p.value = wilcox.test(compliance ~ as.factor(round), paired = T)$p.value,
            statistic = wilcox.test(compliance ~ as.factor(round), paired = T)$statistic)%>% 
  mutate(stage = "peer-enforced")

# Unifying outputs

test.evol <- rbind(evol.nonenf, evol.peerenf) %>% 
  select(performance= performance.nm, frame = frame.nm, stage, statistic, p.value) %>% 
  mutate(p.value.corrected= p.value*8, 
         sign.corrected = ifelse(p.value.corrected < 0.05,"**", "")) # Correcting for 8 hypotheses using Bonferroni

gt(test.evol) %>% 
   fmt_number(columns = vars(p.value), decimals = 3) %>% 
 tab_header(
    title = md("Nonparametric Wilcoxon rank-sum test to test differences between the first and last round in each stage")
  ) %>% 
  tab_source_note(
    source_note = md("Significance level is ajusted using a Bonferroni correction for 8 hypotheses")
  )%>% 
  tab_source_note(
    source_note = md("Tests are ran for paired samples")
  )

```

### 1.d. Evolution of compliance plot

```{r evolution plot by stage, echo = FALSE, message=FALSE, warning=FALSE, include=FALSE}

# Generating variables

db.evol.plot <- DB %>% 
  mutate(stage.three = case_when(round == 1 ~ 'Early',
                                 round == 2 ~ 'Early', 
                                 round == 3 ~ 'Early',
                                 round == 4 ~ 'Mid',
                                 round == 5 ~ 'Mid',
                                 round == 6 ~ 'Mid',
                                 round == 7 ~ 'Mid',
                                 round == 8 ~ 'Late',
                                 round == 9 ~ 'Late',
                                 round == 10 ~ 'Late',
                                 round == 11 ~ 'Early',
                                 round == 12 ~ 'Early', 
                                 round == 13 ~ 'Early',
                                 round == 14 ~ 'Mid',
                                 round == 15 ~ 'Mid',
                                 round == 16 ~ 'Mid',
                                 round == 17 ~ 'Mid',
                                 round == 18 ~ 'Late',
                                 round == 19 ~ 'Late',
                                 round == 20 ~ 'Late')) %>% 
  group_by(performance.nm, frame.nm, stage.nm, stage.three) %>%
  summarize(mean.compliance = mean(compliance),
            sd = sd(compliance),
            n = length(compliance)) %>% 
  ungroup() %>% 
  mutate(error = qnorm(0.975)*(sd/sqrt(n)), 
         ci.low = mean.compliance - error, 
         ci.high = mean.compliance + error,
         stage.three = factor(stage.three, levels = c("Early", "Mid", "Late")))

plot.high <- ggplot(subset(db.evol.plot, performance.nm == "High performance"), aes(x= stage.three, y= mean.compliance, group=frame.nm)) +
  geom_line(aes(col= frame.nm), size = 0.64) +
  geom_point(aes(col = frame.nm), size = 1.3) +
  geom_errorbar(aes(ymin=ci.low, ymax= ci.high, col = frame.nm), width= 0.28) +
  scale_color_manual(values = c("red1", "royalblue3"), labels = c("pseudo OA (Hake)", "CEAR (Loco)"))+
  scale_fill_manual(values = c("red1", "royalblue3"), labels = c("pseudo OA (Hake)", "CEAR (Loco)"))+
  theme_bw() + 
  ggtitle('High performance associations')+
  xlab(expression(bold("Stage"))) +
  ylab(expression(bold("Compliance (%)")))+
  #scale_x_continuous(expand = c(0,0), breaks=c(seq(1,20,1)), labels = c(seq(0,9,1), seq(0,9,1)))+
  scale_y_continuous(limits = c(0,100), breaks = c(seq(0,100,20)), expand = c(0,0))+
  #geom_vline(xintercept=10.5, size=5.4, col= 'white')+
  facet_wrap(~stage.nm)+
  theme(legend.position="bottom", legend.title=element_blank(), legend.text =    element_text(size=11), panel.grid = element_blank(), plot.title = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        #strip.background = element_blank(),
        strip.text = element_text(size= 10, hjust = 0, vjust = 1),
        panel.border = element_rect(colour = "dark grey"), 
        panel.spacing.x=unit(1, "lines"), 
        axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0)), 
        #axis.title = element_text(size = 11), 
        axis.title = element_blank(),
        axis.text = element_text(size = 10),
        plot.title = element_text(size= 11, face= "bold", hjust = 0, vjust = 1))

plot.low <- ggplot(subset(db.evol.plot, performance.nm == "Low performance"), aes(x= stage.three, y= mean.compliance, group=frame.nm)) +
  geom_line(aes(col= frame.nm), size = 0.64) +
  geom_point(aes(col = frame.nm), size = 1.3) +
  geom_errorbar(aes(ymin=ci.low, ymax= ci.high, col = frame.nm), width= 0.28) +
  scale_color_manual(values = c("red1", "royalblue3"), labels = c("pseudo OA (Hake)", "CEAR (Loco)"))+
  scale_fill_manual(values = c("red1", "royalblue3"), labels = c("pseudo OA (Hake)", "CEAR (Loco)"))+
  theme_bw() + 
  ggtitle('High performance associations')+
  xlab(expression(bold("Stage"))) +
  ylab(expression(bold("Compliance (%)")))+
  #scale_x_continuous(expand = c(0,0), breaks=c(seq(1,20,1)), labels = c(seq(0,9,1), seq(0,9,1)))+
  scale_y_continuous(limits = c(0,100), breaks = c(seq(0,100,20)), expand = c(0,0))+
  #geom_vline(xintercept=10.5, size=5.4, col= 'white')+
  facet_wrap(~stage.nm)+
  theme(legend.position="bottom", legend.title=element_blank(), legend.text =    element_text(size=11),
        panel.grid = element_blank(), plot.title = element_text(hjust = 0.5), panel.grid.major =
          element_blank(), panel.grid.minor = element_blank())+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        #strip.background = element_blank(),
        strip.text = element_text(size= 10, hjust = 0, vjust = 1),
        panel.border = element_rect(colour = "dark grey"), 
        panel.spacing.x=unit(1, "lines"), 
        axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0)), 
        axis.title = element_blank(), 
        axis.text = element_text(size = 10),
        plot.title = element_text(size= 11, face= "bold", hjust = 0, vjust = 1))

evol.compliance <- gridExtra::grid.arrange(plot.high, plot.low, ncol = 2)

evol.compliance
#ggsave("Fig3.pdf", plot = evol.compliance, device = "pdf", path = here::here("figures"), scale = 1, width = 18, height = 12, units = "cm", dpi = 300, limitsize = TRUE)

```

# 3. Determinants of compliance in the game

```{r linear mixed models of compliance at the individual level in peer-enforced stage with random effects, echo = FALSE}

comp_ind_hp_cear <- lme(compliance ~ avg_comp_non_enf + avg_oth_comp_prev +  punished_prev_round + punished_prev_prev_round + report_prev_round + peer_enf_rounds, random=~1|id, na.action= na.exclude, data = filter(db.ind, hp == 1 & frame.nm =="Loco" & stage.nm == 'Peer-enforced'))

comp_ind_hp_oa <- lme(compliance ~ avg_comp_non_enf + avg_oth_comp_prev +  punished_prev_round + punished_prev_prev_round + report_prev_round + peer_enf_rounds, random=~1|id, na.action= na.exclude, data = filter(db.ind, hp == 1 & frame.nm =="Hake" & stage.nm == 'Peer-enforced'))

comp_ind_lp_cear <- lme(compliance ~ avg_comp_non_enf + avg_oth_comp_prev +  punished_prev_round + punished_prev_prev_round + report_prev_round + peer_enf_rounds, random=~1|id, na.action= na.exclude, data = filter(db.ind, hp == 0 & frame.nm =="Loco" & stage.nm == 'Peer-enforced'))

comp_ind_lp_oa <- lme(compliance ~ avg_comp_non_enf + avg_oth_comp_prev +  punished_prev_round + punished_prev_prev_round + report_prev_round + peer_enf_rounds, random=~1|id, na.action= na.exclude, data = filter(db.ind, hp == 0 & frame.nm =="Hake" & stage.nm == 'Peer-enforced'))

# printing results

summary(comp_ind_hp_cear)
intervals(comp_ind_hp_cear)

summary(comp_ind_hp_oa)
intervals(comp_ind_hp_oa)

summary(comp_ind_lp_cear)
intervals(comp_ind_lp_cear)

summary(comp_ind_lp_oa)
intervals(comp_ind_lp_oa)

```

```{r tobit mixed models of compliance at the individual level in peer-enforced stage with random effects, echo = FALSE}

# transforming to panel

db.ind <- data.frame(db.ind)
panel.db.hp.cear <- plm::pdata.frame(filter(db.ind, hp == 1 & frame.nm =="Loco" & stage.nm == "Peer-enforced"), c("id", "round"))
panel.db.hp.oa <- plm::pdata.frame(filter(db.ind, hp == 1 & frame.nm =="Hake" & stage.nm == "Peer-enforced"), c("id", "round"))
panel.db.lp.cear <- plm::pdata.frame(filter(db.ind, hp == 0 & frame.nm =="Loco" & stage.nm == "Peer-enforced"), c("id", "round"))
panel.db.lp.oa <- plm::pdata.frame(filter(db.ind, hp == 0 & frame.nm =="Hake" & stage.nm == "Peer-enforced"), c("id", "round"))

# computing tobit with individual random effects with BHHH mthod for convergence

tobit_comp_ind_hp_cear <- censReg(compliance ~ avg_comp_non_enf + avg_oth_comp_prev +  punished_prev_round +  punished_prev_prev_round+ report_prev_round + peer_enf_rounds, left = 0, right = 100, data = panel.db.hp.cear, method = "BHHH")

tobit_comp_ind_hp_oa <- censReg(compliance ~ avg_comp_non_enf + avg_oth_comp_prev +  punished_prev_round + punished_prev_prev_round + report_prev_round + peer_enf_rounds, left = 0, right = 100, data = panel.db.hp.oa, method = "BHHH")

tobit_comp_ind_lp_cear <- censReg(compliance ~ avg_comp_non_enf + avg_oth_comp_prev +  punished_prev_round +  punished_prev_prev_round + report_prev_round + peer_enf_rounds, left = 0, right = 100, data = panel.db.lp.cear, method = "BHHH")

tobit_comp_ind_lp_oa <- censReg(compliance ~ avg_comp_non_enf + avg_oth_comp_prev +  punished_prev_round + punished_prev_prev_round + report_prev_round + peer_enf_rounds, left = 0, right = 100, data = panel.db.lp.oa, method = "BHHH")


# print results

summary(tobit_comp_ind_hp_cear)
confint(tobit_comp_ind_hp_cear)

summary(tobit_comp_ind_hp_oa)
confint(tobit_comp_ind_hp_oa)

summary(tobit_comp_ind_lp_cear)
confint(tobit_comp_ind_lp_cear)

summary(tobit_comp_ind_lp_oa)
confint(tobit_comp_ind_lp_oa)
```


### 4. Determinants of individual reporting decisions 


```{r report probit models at the individual level, echo = FALSE}

# selecting only subjects that had the opportunity to punish

report_hp_cear <- glm(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + avg_oth_comp_prev + punished_prev_round + punished_prev_prev_round + peer_enf_rounds, na.action= na.exclude, data = filter(db.ind, hp == 1 & frame.nm =="Loco" & observer == 1 & overext_observed > 0), family = binomial(link = "probit"))

report_hp_oa <- glm(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + avg_oth_comp_prev + punished_prev_round + punished_prev_prev_round + peer_enf_rounds, na.action= na.exclude, data = filter(db.ind, hp == 1 & frame.nm =="Hake" & observer == 1 & overext_observed > 0), family = binomial(link = "probit"))

report_lp_cear <- glm(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + avg_oth_comp_prev + punished_prev_round + punished_prev_prev_round + peer_enf_rounds, na.action= na.exclude, data = filter(db.ind, hp == 0 & frame.nm =="Loco" & observer == 1 & overext_observed > 0), family = binomial(link = "probit"))

report_lp_oa <- glm(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + avg_oth_comp_prev + punished_prev_round + punished_prev_prev_round + peer_enf_rounds, na.action= na.exclude, data = filter(db.ind, hp == 0 & frame.nm =="Hake" & observer == 1 & overext_observed > 0), family = binomial(link = "probit"))

# printing results

summary(report_hp_cear)
confint(report_hp_cear)

summary(report_hp_oa)
confint(report_hp_oa)


summary(report_lp_cear)
confint(report_lp_cear)

summary(report_lp_oa)
confint(report_lp_oa)
```


```{r report probit models at the individual level with random effects, echo = FALSE}

# from https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/

## models fail converge with too many variables so I removed average contribution of others in previous round, the second lag of punishment and round

report_hp_cear_re <- glmer(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + punished_prev_round + (1|id), na.action= na.exclude, data = filter(db.ind, hp == 1 & frame.nm =="Loco" & observer == 1 & overext_observed > 0), family = binomial(link = "probit"))

report_hp_oa_re <- glmer(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + punished_prev_round + (1|id), na.action= na.exclude, data = filter(db.ind, hp == 1 & frame.nm =="Hake" & observer == 1 & overext_observed > 0), family = binomial(link = "probit"))

report_lp_cear_re <- glmer(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + punished_prev_round + (1|id), na.action= na.exclude, data = filter(db.ind, hp == 0 & frame.nm =="Loco" & observer == 1 & overext_observed > 0), family = binomial(link = "probit"))

report_lp_oa_re <- glmer(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + punished_prev_round + (1|id), na.action= na.exclude, data = filter(db.ind, hp == 0 & frame.nm =="Hake" & observer == 1 & overext_observed > 0), family = binomial(link = "probit"))

# print the mod results without correlations among fixed effects

summary(report_hp_cear_re)

summary(report_hp_oa_re)

summary(report_lp_cear_re)

summary(report_lp_oa_re)


```

```{r report linear models at the individual level, echo = FALSE}

# selecting only subjects that had the opportunity to punish

lm_report_hp_cear <- lm(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + avg_oth_comp_prev + punished_prev_round + punished_prev_prev_round + peer_enf_rounds, na.action= na.exclude, data = filter(db.ind, hp == 1 & frame.nm =="Loco" & observer == 1 & overext_observed > 0))

lm_report_hp_oa <- lm(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + avg_oth_comp_prev + punished_prev_round + punished_prev_prev_round + peer_enf_rounds, na.action= na.exclude, data = filter(db.ind, hp == 1 & frame.nm =="Hake" & observer == 1 & overext_observed > 0))

lm_report_lp_cear <- lm(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + avg_oth_comp_prev + punished_prev_round + punished_prev_prev_round + peer_enf_rounds, na.action= na.exclude, data = filter(db.ind, hp == 0 & frame.nm =="Loco" & observer == 1 & overext_observed > 0))

lm_report_lp_oa <- lm(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + avg_oth_comp_prev + punished_prev_round + punished_prev_prev_round + peer_enf_rounds, na.action= na.exclude, data = filter(db.ind, hp == 0 & frame.nm =="Hake" & observer == 1 & overext_observed > 0))

# printing results

summary(lm_report_hp_cear)
confint(lm_report_hp_cear)

summary(lm_report_hp_oa)
confint(lm_report_hp_oa)


summary(lm_report_lp_cear)
confint(lm_report_lp_cear)

summary(lm_report_lp_oa)
confint(lm_report_lp_oa)
```


```{r report linear models at the individual level with random effects, echo = FALSE}

# from https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/

## models fail converge with too many variables so I removed average contribution of others in previous round, the second lag of punishment and round

lm_report_hp_cear_re <- lmer(report ~ avg_comp_non_enf + neg_comp_inspected_deviation + pos_comp_inspected_deviation + diff_comp_group_comp_prev + punished_prev_round + (1|id), na.action= na.exclude, data = filter(db.ind, hp == 1 & frame.nm =="Loco" & observer == 1 & overext_observed > 0))



```




